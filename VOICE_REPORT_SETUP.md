# 音声入力による報告機能 - セットアップガイド

週次会議で、メンバーが口頭で報告した内容を音声認識で取り込み、AIで自動要約して報告フォーマットに反映する機能です。

## 📋 機能概要

1. **音声認識**: Web Speech API（ブラウザ標準）でリアルタイム音声入力
2. **AI要約**: Google Gemini APIで自動要約・構造化
3. **自動反映**: 既存の報告フォーマット（今試していること、経過報告、結果報告・考察）に自動で振り分け

## 🚀 セットアップ手順

### 1. Google Gemini APIキーの取得

1. [Google AI Studio](https://aistudio.google.com/app/apikey) にアクセス
2. Googleアカウントでログイン
3. 「Create API Key」をクリック
4. APIキーをコピー

### 2. 環境変数の設定

`.env.local` ファイルを作成（または編集）して、以下を追加：

```bash
# Google Gemini API Configuration
NEXT_PUBLIC_GEMINI_API_KEY=your-actual-api-key-here
```

> **注意**: APIキーは必ず `.env.local` に保存し、Gitにコミットしないでください。

### 3. パッケージのインストール

```bash
npm install
```

Gemini APIライブラリ（`@google/generative-ai`）がインストールされます。

### 4. 開発サーバーの起動

```bash
npm run dev
```

## 💡 使い方

### 基本的な使い方

1. **ログイン**: 管理者アカウントでログイン
2. **報告ページへ移動**: メニューから「経過報告」を選択
3. **編集モードON**: 鉛筆アイコンをタップ
4. **音声入力開始**: 各報告カードの「🎤 音声で報告を入力」ボタンをタップ
5. **報告を話す**: マイクに向かって今週の報告を話す
6. **完了**: 「完了してAI要約」ボタンをタップ
7. **確認**: AI要約された内容が自動的に3つの項目に振り分けられます
8. **保存**: 内容を確認して「保存」ボタンをタップ

### 会議での使い方（推奨）

**シーン**: 毎週のリアルミーティングで、メンバーが順番に報告

1. 司会者がログインして編集モードON
2. 報告者のカードの音声入力ボタンをタップ
3. 報告者が話し始める（音声認識が自動でテキスト化）
4. 報告が終わったら「完了してAI要約」
5. AIが自動で要約・整形（5〜10秒程度）
6. 次の報告者へ
7. 全員終了後、まとめて「保存」

## 🎤 音声入力のコツ

### ✅ うまくいくポイント

- **明瞭に話す**: はっきりとした発音で
- **適度な速度**: 早口すぎず、ゆっくりすぎず
- **静かな環境**: 周囲の雑音が少ない場所で
- **マイクに近づく**: 特にスマホの場合
- **区切りを意識**: 「今週やったことは...」「結果として...」など

### ⚠️ 注意点

- **ブラウザ対応**: Chrome、Edge、Safariを推奨（Firefoxは非対応）
- **マイク許可**: 初回は必ずマイクアクセスを許可
- **ネット接続**: 音声認識とAI要約の両方でネット接続が必要
- **処理時間**: AI要約に5〜10秒かかります

## 🔧 トラブルシューティング

### 音声認識が動かない

**「お使いのブラウザは音声認識に対応していません」と表示される**
- ✅ Chrome、Edge、Safariを使用してください
- ✅ HTTPSまたはlocalhostで実行していることを確認

**マイクが反応しない**
- ✅ ブラウザのマイクアクセス許可を確認
- ✅ システム設定でマイクが有効か確認
- ✅ 他のアプリがマイクを使用していないか確認

### AI要約が動かない

**「Gemini APIキーが設定されていません」と表示される**
- ✅ `.env.local` にAPIキーを正しく設定
- ✅ 開発サーバーを再起動（`npm run dev`）

**「AI要約に失敗しました」と表示される**
- ✅ APIキーが有効か確認（Google AI Studioで確認）
- ✅ ネット接続を確認
- ✅ Gemini APIの利用上限を確認（無料枠: 60リクエスト/分）

### 要約の品質が低い

- ✅ より具体的に話す（数字、固有名詞を含める）
- ✅ 3つの項目を意識して話す（今やっていること、経過、結果）
- ✅ 長すぎる場合は分けて入力

## 📊 コスト

### Web Speech API
- **完全無料**（ブラウザ標準機能）

### Google Gemini API
- **無料枠**: 60リクエスト/分、1,500リクエスト/日
- **十分な枠**: 週次報告（10人）なら十分無料で使える
- 詳細: [Gemini API Pricing](https://ai.google.dev/pricing)

## 🔐 セキュリティ

- APIキーは `.env.local` に保管（Gitには含めない）
- `NEXT_PUBLIC_` プレフィックスでブラウザから利用可能
- 本番環境ではサーバーサイドAPI経由を推奨（将来の改善）

## 📝 データフォーマット

AIは以下の3項目に自動で振り分けます：

```typescript
{
  currentTrial: "今試していること（現在取り組んでいる課題や試行）",
  progress: "経過報告（今週やったこと、進捗状況）",
  result: "結果報告・考察（得られた結果、気づき、次のアクション）"
}
```

## 🎯 今後の改善案

- [ ] 音声認識の精度向上（Google Cloud Speech-to-Text統合）
- [ ] 複数言語対応
- [ ] 音声データの一時保存・再生機能
- [ ] カスタムプロンプト編集機能
- [ ] 報告テンプレートの柔軟な設定

## 📞 サポート

質問や不具合がある場合は、開発チームまでご連絡ください。
